---
title             : "The title"
shorttitle        : "Title"

author: 
  - name          : "Karolina Muszyńska"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "University of Warsaw, Faculty of Psychology, ul. Stefana Banacha 2D, 02-097 Warsaw, Poland"
    email         : "karolina.muszynska@psych.uw.edu.pl"
    role: # Contributorship roles (e.g., CRediT, https://credit.niso.org/)
      - "Conceptualization"
      - "Writing - Original Draft Preparation"
      - "Writing - Review & Editing"
  - name          : "To fill in later on"
    affiliation   : "2"
    role:
      - "Writing - Review & Editing"
      - "Supervision"

affiliation:
  - id            : "1"
    institution   : "University of Warsaw, Faculty of Psychology"
  - id            : "2"
    institution   : "To fill in later on"

abstract: |
  Abstract here
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : "r-references.bib"

floatsintext      : yes
linenumbers       : yes
draft             : no
mask              : no

figurelist        : no
tablelist         : no
footnotelist      : no

classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}

library(papaja)
r_refs("r-references.bib")

library(tidyverse)
library(Multilada)
library(here)


```

```{r analysis-preferences}
# Seed for random number generation
set.seed(123)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed, echo = F, include = F, warning = F, message = F, out.width="100%")
```


```{r, echo = F}
# Data
source(here("data/polish/data_polish.R"))
source(here("data/english/data_ame_english.R"))
```

# Methods

## Participants

```{r}
# the two groups differ by age
t_age <- apa_print(t.test(by_child_pl$age_CAT, kept_demo$age_cat))
```


In the American English validation study, the participants were 204 parents of children aged 15 to 36 months (*M* = `r round(mean(kept_demo$age_cat),2)`, *Mdn* = `r round(median(kept_demo$age_cat),2)`, SD = `r round(sd(kept_demo$age_cat),2)`). There were 103 girls in the sample (`r round(sum(kept_demo$sex_cat == "F")/count(kept_demo)*100,2)`%). The sample was ethnically diverse, including White, Black, Latino/Hispanic, Asian, Native American, and other races/ethnicities. None of the children were reported to hear other languages apart from English. <!-- as checked in kept_demo$other_languages --> The average
number of years of education attained by the primary caregiver was `r round(mean(kept_demo$primary_education_cat),2)` (SD = `r round(sd(kept_demo$primary_education_cat),2)`).

In the Polish validation study, the participants were 113 parents of children aged 18 to 34 months (*M* = `r round(mean(by_child_pl$age_CAT),2)`, *Mdn* = `r round(median(by_child_pl$age_CAT),2)`, SD = `r round(sd(by_child_pl$age_CAT),2)`). There were 49 girls in the sample (`r round(sum(by_child_pl$sex == "dziewczynka")/count(by_child_pl)*100,2)`%). The sample was White (reflecting the limited ethnic diversity within the Polish population). However, there were 28 children multilingual with Polish (as their home language) and some other (majority) language. [todo: add info on parental edu]


## Materials
The data was gathered with CAT-CDIs in American English and Polish. The American English CAT-CDI was created from the items that were common to three CDIs: Words and Gestures, Words and Sentences and CDI-III. With these items, two CAT-CDIs were created, one for word production and another for word comprehension (see Kachergis et al. 2022 for more details). The Polish CAT-CDIs were created following a largely similar procedure as the ones in American English, but there was a separate CDI-CAT developed for each CDI version (CDI: Words and Gestures and CDI: Words and Sentences) and for each CDI:WG subscale (word production, word comprehension, gesture use) (Krajewski et al. in preparation). Here we show data from the validation study of American English CAT-CDI word production (i.e. 679 items) and Polish CAT-CDI version of WS: Words and Sentences (i.e. 666 items). There are 395 words that appear in both CDI-CAT language versions. 

## Procedure
Though in both validation studies the parents were asked to fill in both the full CDI and the CAT-CDI, the procedure differed between the two validation studies. In the validation of American English CDI-CAT, parents were given both CDIs in one sitting, but the order of the CDI versions was counterbalanced. In the Polish validation study, the order of the CDIs was fixed, with the full CDI always first, and then, after 1–30 days (*M* = `r round(mean(by_child_pl$days_between),2)`, *Mdn* = `r round(median(by_child_pl$days_between),2)`, SD = `r round(sd(by_child_pl$days_between),2)`) parents were asked to fill in the CAT-CDI. Both studies were done fully online and obtained the approval of adequate ethics committees.

# Results

## Psychometric properties of the two CAT-CDIs

Our first aim was to examine whether CAT-CDIs in American English and Polish demonstrate comparable psychometric properties. To that end, we revisit the psychometric properties reported for the American English CAT-CDI (word production) in Kachergis et al. (2022) and compare those to the data from Polish CAT-CDI (Words and Sentences).

<!-- AmE r values copied from Kachergis et al. 2022 -->
```{r}
cor(by_child_pl$cat_theta, by_child_pl$score_full) # AmE:.86, PL: 0.86
cor(by_child_pl$cat_theta, by_child_pl$full_theta) # AmE: .92, PL: .92
cor(by_child_pl$full_theta, by_child_pl$score_full) # AmE: .95, PL: 0.94

```

We found similarly strong correlations in the two languages between the abilities estimated from CDI-CAT and full CDI scores (American English and Polish: $r$ = .86), the abilities estimated from the CDI-CAT and abilities estimated from full CDI (American English and Polish: $r$ = .92), and the abilities estimated from the full CDI and the full CDI scores (American English: $r$ = .95, Polish: $r$ = `r cor(by_child_pl$full_theta, by_child_pl$score_full)`). The abilities estimated from the CDI-CAT and the full CDI scores were also strongly correlated within individual age groups (see Table \@ref(tab:corr-by-age)).


```{r corr-by-age, include = T}

# TODO:
# 1. merge both tables?
# 2. can we specify place in text where the tables should be placed (rn it seems random)

# English
valid_tab <- prod_s %>% 
  mutate(age_group = cut(age_full, breaks=seq(12,36,3), right=F, include.lowest = T)) %>%
  group_by(age_group) %>%
  summarise(r = cor(fullTheta, catTheta), n=n()) #%>% kableExtra::kable(digits=2)

valid_tab_wide = rbind(round(valid_tab$r, 2), as.character(valid_tab$n))
colnames(valid_tab_wide) = as.character(valid_tab$age_group)
row.names(valid_tab_wide) = c('r ability CAT vs full CDI', 'N')

apa_table(valid_tab_wide, caption="American English: Correlations between ability estimated by CAT-CDI and ability estimated from full CDI by children's age", placement = "H") 

# Polish
age_cor_table <- by_child_pl %>% 
  mutate(age_group = cut(age_CAT, breaks=seq(12,36,3), right=F, include.lowest = T)) %>%
  group_by(age_group) %>%
  summarise(r = cor(full_theta, cat_theta), n=n())

age_cor_table_wide = rbind(round(age_cor_table$r, 2), as.character(age_cor_table$n))
colnames(age_cor_table_wide) = as.character(age_cor_table$age_group)
row.names(age_cor_table_wide) = c('r ability CAT vs full CDI', 'N')

apa_table(age_cor_table_wide, caption = "Polish: Correlations between ability estimated by CAT-CDI and ability estimated from full CDI by children's age", placement = "H")
```

The Polish validation study included `r sum(by_child_pl$lang_group == "multilingual")` data from bi- and multilingual families. Though it is a small group, we decided to explore their correlation coefficients (non-parametric Spearman's rho) and found these were similar to those found for Polish monolingual children (see Table \@ref(tab:corr-by-langgroup) in Supplementary Materials). 

```{r corr-by-langgroup, include = T}

# TODO: 
# 1. the table could use some re-styling (lgs as columns?)
# 2. move to Supplementary (separate .Rmd?)

cor1 <- by_child_pl %>%
  group_by(lang_group) %>%
  summarise(r = cor(cat_theta, score_full, method = "spearman"), n = n()) %>%
  mutate(correlation = "Ability from CDI-CAT ~ full CDI score")

cor2 <- by_child_pl %>%
  group_by(lang_group) %>%
  summarise(r = cor(cat_theta, full_theta, method = "spearman"), n = n()) %>%
  mutate(correlation = "Ability from CDI-CAT ~ ability from full CDI")

cor3 <- by_child_pl %>%
  group_by(lang_group) %>%
  summarise(r = cor(full_theta, score_full, method = "spearman"), n = n()) %>%
  mutate(correlation = "Ability from full CDI ~ full CDI score")

lang_cor_table <- bind_rows(cor1, cor2, cor3)
rm(cor1, cor2, cor3)

apa_table(lang_cor_table, caption = "Supplementary Material: Table S1 - Spearman's correlations for monolingual and multilingual children in the Polish dataset", placement = "H")

```

```{r mse}
# TODO
# 1. Eng values shifted slightly? 

# Polish
by_child_pl <- by_child_pl %>% mutate(sq_err = (full_theta - cat_theta)^2,
                                      full_cat_diff = full_theta - cat_theta)
mean(by_child_pl$sq_err) # 0.19
median(by_child_pl$sq_err) # 0.08
sd(by_child_pl$sq_err) # 0.45

bad_thresh_pl <- mean(by_child_pl$sq_err) + 1.5*sd(by_child_pl$sq_err)
bad_thresh_pl # 0.86

by_child_pl <- by_child_pl %>% mutate(extreme_discrep = 
                                           case_when(
                                                sq_err > bad_thresh_pl ~ "yes",
                                                .default = "no"
                                           ))

table(by_child_pl$extreme_discrep)

# English

# mean squared error
prod_s <- prod_s %>% mutate(sq_err = (fullTheta - catTheta)^2,
                            full_cat_diff = fullTheta - catTheta)

bad_thresh_en <- mean(prod_s$sq_err) + 1.5*sd(prod_s$sq_err) # mean=.55, med = .17

# bad_en <- subset(prod_s, sq_err > bad_thresh_en) # 18 --> 15?
# good_en <- subset(prod_s, sq_err <= bad_thresh_en) # 186 --> 189?

prod_s <- prod_s %>% mutate(extreme_discrep = 
                                           case_when(
                                                sq_err > bad_thresh_en ~ "yes",
                                                .default = "no"
                                           ))

table(prod_s$extreme_discrep)


```

```{r duration-full}

# Polish
mean(by_child_pl$duration_full) # 133892.9 sec
sd(by_child_pl$duration_full) # 980822.7 sec
# sd larger than mean - highly skewed

ecdf_fun <- ecdf(as.numeric(by_child_pl$duration_full))
by_child_pl <- by_child_pl %>%
  mutate(duration_full_percentile = ecdf_fun(duration_full) * 100)

# English
# create and attach duration_full to prod_s

demo <- demo %>% mutate(
     duration_full = lubridate::as.duration(last_modified_full - created_date_full))
prod_s <- merge(prod_s, demo[,c("subject_id", "duration_full")], all.x = T, by = "subject_id")

ecdf_fun <- ecdf(as.numeric(prod_s$duration_full))
prod_s <- prod_s %>%
  mutate(duration_full_percentile = ecdf_fun(duration_full) * 100)

prod_s %>% ggplot(aes(y = duration_full, x = extreme_discrep)) + geom_jitter(alpha = 0.3)
# extreme_discrep cases are scattered across the whole range of durations

```


We also looked at the mean squared error between the abilities as estimated by CAT-CDI and from the full CDI. The mean squared error in English was 0.55 (*Mdn* = 0.17, *SD* = 1), and in Polish it was `r mean(by_child_pl$sq_err)` (*Mdn* = `r median(by_child_pl$sq_err)`, *SD* = `r sd(by_child_pl$sq_err)`). We then zoomed in on children for whom the estimates from the CAT-CDI and full CDI diverged extremely, i.e. their difference between the errors was 1.5 SD from the mean. There were `r sum(prod_s$extreme_discrep == "yes")` such cases (`r round(sum(prod_s$extreme_discrep == "yes")/count(prod_s)*100,2)`%) in the English dataset and `r sum(by_child_pl$extreme_discrep == "yes")` cases (`r round(sum(by_child_pl$extreme_discrep == "yes")/count(prod_s)*100,2)`%) in the Polish dataset. All participants in both datasets showed higher ability estimates on the CDI-CAT compared to the full CDI. If the full CDI is considered the baseline, this suggests that parents may have overestimated their child’s vocabulary on the CDI-CAT, potentially responding “yes – produces” to more items than expected based on full CDI estimates (as suggested by Kachergis, et al. 2022). An alternative explanation is that, for these participants, the full CDI may have underestimated the child’s true ability. Notably, all Polish participants with large discrepancies completed the full CDI in unusually short times (their completion times were among the shortest 5% in the sample) suggesting their responses may have been rushed or less attentive. This could have led to lower ability estimates from the full CDI and larger discrepancies between estimates from full and CAT CDI. Supporting this interpretation, their CDI-CAT scores had acceptable measurement errors (below or equal to 0.1 for Polish), indicating reliable ability estimation by the CDI-CAT, in contrast to the full CDI. This was partially true for the American sample - though only 2 participants had similarly short full CDIs, all but two showed relatively low measurement errors (more on measurement error in Section XX).

```{r, include = F}
# participants with extreme discrepancy in English dataset:
extreme_discrep <- prod_s %>% filter(extreme_discrep == "yes") %>% select(-subject_id, duration_full_percentile)
# write.csv2(extreme_discrep, "extreme_discrep_en.csv")
```

```{r}
prod_s %>% filter(extreme_discrep == "no") %>% summarise(mean(sq_err)) # 0.44, was 0.55
by_child_pl %>% filter(extreme_discrep == "no") %>% summarise(mean(sq_err)) # 0.12, was 0.19
```

We also re-calculated the mean squared error without the cases of extreme discrepancy, which yielded a MSE of `r round(prod_s %>% filter(extreme_discrep == "no") %>% summarise(mean(sq_err)),2)` (*Mdn* = `r round(prod_s %>% filter(extreme_discrep == "no") %>% summarise(median(sq_err)),2)`, *SD* = `r round(prod_s %>% filter(extreme_discrep == "no") %>% summarise(sd(sq_err)),2)`) in English and MSE of `r round(by_child_pl %>% filter(extreme_discrep == "no") %>% summarise(mean(sq_err)),2)` (*Mdn* = `r round(by_child_pl %>% filter(extreme_discrep == "no") %>% summarise(median(sq_err)),2)`, *SD* = `r round(by_child_pl %>% filter(extreme_discrep == "no") %>% summarise(sd(sq_err)),2)`) in Polish.

## Item properties in the two CAT-CDIs
Our second aim was to analyze similarities and differences in IRT item properties and item selection in CAT in English and Polish.

There are 679 items in the English CAT-CDI and 666 items in the Polish CAT-CDI. For both sets of items, the items' difficulty and discrimination parameters were calculated using IRT 2 parameter model (these included separate samples, see Kachergis et al. 2022 and Krajewski et al. (in preparation)). An item’s difficulty indicates the ability level at which there is a 50% probability that a participant will respond correctly <!-- SEE ISSUE 1: https://github.com/karolina-m/catcdi_validation_eng_pl/issues/1 -->. It is on the same scale as ability with negative values indicating difficult items, values around 0 indicating medium difficulty, and positive values indicating easy items. <!-- we should probably add a footnote here explaining that d is kind of inversely related to theta and so negative ability means low while positive ability means high. --> An item’s discrimination indicates how well it distinguishes between individuals with slightly different ability levels--especially those near that difficulty point. Of these two parameters, item difficulty is of greater interest to the present paper as it is directly linked to ability and as discrimination power is more about how good the item is at measuring, rather than what it is measuring.<!-- this could potentially go up, into Intro/Methods? -->

```{r diff_across_lgs}
# item difficulty by language 
items_cat_en %>% 
     dplyr::summarise(min(d), max(d), mean(d), median(d), sd(d))

items_cat_pl %>% 
     dplyr::summarise(min(d), max(d), mean(d), median(d), sd(d))

t1 <- apa_print(t.test(items_cat_en$d, items_cat_pl$d))

```

```{r common_items}
# common items - still different mean difficulty?

items_en_pl <- merge(items_cat_pl, items_cat_en, 
                  all.x = T, all.y = T,
                  suffixes = c("_pl","_en"),
                  by = "uni_lemma") %>% filter(!is.na(item) & !is.na(definition))
count(items_en_pl) # 390

t2 <- apa_print(t.test(items_en_pl$d_en, items_en_pl$d_pl, paired = T))
# t = -23.112, df = 389, p-value < 2.2e-16

# visualise
items_en_pl %>% select(uni_lemma, d_pl, d_en) %>% pivot_longer(cols = d_pl:d_en, names_to = "lang", values_to = "d") %>% ggplot(aes(x = lang, y = d, group = lang)) + geom_boxplot() + geom_jitter(alpha = 0.3)

items_en_pl %>% select(uni_lemma, d_pl, d_en) %>% 
     ggplot(aes(x = d_pl, y = d_en)) + geom_jitter(alpha = 0.3) + geom_smooth(method = "lm") +
     stat_cor(cor.coef.name = "r", p.accuracy = 0.001, r.accuracy = 0.01, size = 5, show.legend = F) +
     theme_light() + labs(x = "Item difficulty in Polish", y = "Item difficulty in English")

# corr
c <- apa_print(cor.test(items_en_pl$d_pl, items_en_pl$d_en)) # 0.65
```

English items are more difficult than the Polish items, `r t1$full_result` (English: min = `r round(min(items_cat_en$d),2)`, max = `r round(max(items_cat_en$d),2)`, *M* = `r round(mean(items_cat_en$d),2)`, *Mdn* = `r round(median(items_cat_en$d),2)`, *SD* = `r round(sd(items_cat_en$d),2)`; Polish: min = `r round(min(items_cat_pl$d),2)`, max = `r round(max(items_cat_pl$d),2)`, *M* = `r round(mean(items_cat_pl$d),2)`, *Mdn* = `r round(median(items_cat_pl$d),2)`, *SD* = `r round(sd(items_cat_pl$d),2)`). Notably, this was true even for a subset of `r count(items_en_pl)` items common to both languages - these items still proved to be more difficult in English than in Polish: `r t2$full_result`. This difference in mean difficulty may be influenced by the characteristics of the samples used to estimate the IRT models. In English, item difficulty was calculated based on a broader sample of children aged 12–36 months (spanning the CDI:WG, CDI:WS, and CDI-III), whereas the Polish data came from a sample of narrower age range of 18–36 months, corresponding to the CDI:WS. As a result, item difficulty in English was estimated using a relatively younger sample, for whom certain items may have been more challenging—thus appearing more difficult—compared to the older Polish sample. Still the item difficulty for common items in the two languages was positively and moderately correlated: `r c$full_result`.

```{r d_by_cdi_category_tab, include = T}
# correlations by cdi semantic category on common words
# spearman because ranked

items_en_pl %>% group_by(category_pl) %>% summarise(
     rho = cor(d_pl, d_en, method = "spearman", use = "complete.obs"),
     n = length(category_pl)) %>% arrange(rho) -> corr_by_category

apa_table(corr_by_category, placement = "H")
```

```{r d-by-cdi-category-fig, fig.width = 10, fig.height = 5, fig.cap = "The relative positioning of the items by semantic category (colored) plotted in the context of the full item pool (grey): (A) English, (B) Polish.", fig.pos = '!h', include = T}

# TODO: adjust order, put "helping_verbs" at the end

# AMERICAN ENGLISH
fig1a <- items_cat_en %>%
ggplot(aes(d, a1))  + 
  geom_point(data = items_cat_en %>%
               select(-category), aes(x = d, y = a1), color = 'grey', size = 0.4) +
  geom_point(aes(color=as.factor(category)), size = 0.4) +
  facet_wrap(~category) +
  xlim(-8, 8) +
  ylim(0,8) +
  labs(x = "Item difficulty (d)", y = "Item discrimination (a1)", title = "(A) English") +
  theme(legend.position = "none")

# TODO: adjust order, put "modal_adverbs" and "prepositions" at the end

# POLISH
fig1b <- items_cat_pl %>%
  mutate(category = case_when(
    category == "descriptive_words (adjectives)" ~ "descriptive_words",
    category == "descriptive_words (adverbs)" ~ "descriptive_words",
    category == "pronouns_demonstrative" ~ "pronouns",
    category == "pronouns_personal" ~ "pronouns",
    .default = category
  )) %>%
  filter(!is.na(category)) %>% # tylko has category == NA
ggplot(aes(d, a1))  + 
  geom_point(data = items_cat_pl %>%
               select(-category), aes(x = d, y = a1), color = 'grey', size = 0.4) +
  geom_point(aes(color=as.factor(category)), size = 0.4) +
  facet_wrap(~category)  +
  xlim(-8, 8) +
  ylim(0,8) +
  labs(x = "Item difficulty (d)", y = "Item discrimination (a1)", title = "(B) Polish") +
  theme(legend.position = "none")

fig1 <- ggarrange(fig1a, fig1b, ncol = 2, nrow = 1)
fig1
ggsave("fig1.jpeg", dpi = 400, width = 300, height = 150, units = "mm")

```
```{r d_by_cdi_category_tab, include = T}
# correlations by lexical class on common words
# spearman because ranked

items_en_pl <- merge(items_cat_pl, items_cat_en, 
                  all.x = T, all.y = T,
                  suffixes = c("_pl","_en"),
                  by = "uni_lemma") %>% filter(!is.na(item) & !is.na(definition))

items_en_pl %>% group_by(lexical_class_en) %>% summarise(
     rho = cor(d_pl, d_en, method = "spearman", use = "complete.obs"),
     n = length(lexical_class_en)) %>% arrange(rho) -> corr_by_lex_class

apa_table(corr_by_lex_class, placement = "H")
```

We also wanted to do check whether items in particular CDI semantic categories show related difficulty values across the two languages. We performed a series of Spearman's rank correlations (on the difficulty of items common to CDI-CATs in Polish and English) for each CDI semantic category (see Table \@ref(tab:d_by_cdi_category_tab)). The rank correlations coefficients vary by category, but for half of the categories the correlations are moderate to strong (0.52 to 0.91). Figure \@ref(fig:d-by-cdi-category-fig) shows the relative positioning of the items by semantic category (colored) plotted in the context of the full item pool (grey) in the two languages. It can be seen from the figure that many categories (e.g., sounds) show a similar distribution of items relative to the whole item pool across Polish and English.

Last, we investigated whether particular lexical categories show related difficulty values across the two languages. Again, we performed a series of Spearman's rank correlations (on the difficulty of items common to CDI-CATs in Polish and English) for each lexical class (see Table ?). The lowest correlation was for function words (0.40), then verbs (0.47), adjectives (0.53), nouns (0.6), other, i.e. mostly sounds and words relating to routines (e.g. hello, yes, thank you) and time (e.g. tommorow, day) (0.75).

```{r}
# lexical class

# PL
items_cat_pl <- merge(items_cat_pl, items_full_pl[,c("item_id", "lexical_class")], all.x = T, 
                      by.x = "itemID", by.y = "item_id") 

# removing some lexical classes from PL that do not appear in EN
lex_pl <- items_cat_pl %>%
     filter(!lexical_class %in% c("adverbs", "conjunctions", "modal_adverbs", "prepositions")) %>%
     ggplot(aes(d, a1))  + 
     geom_point(data = items_cat_pl %>%
               select(-lexical_class), aes(x = d, y = a1), color = 'grey', size = 0.4) +
  geom_point(aes(color=as.factor(lexical_class)), size = 0.4) +
  facet_wrap(~lexical_class)  +
  xlim(-7, 7) +
  ylim(0,7) +
  labs(x = "Item difficulty (d)", y = "Item discrimination (a1)", title = "(B) Polish") +
  theme(legend.position = "none")

# EN
items_full_en <- read.csv("data/english/eng_ws_items.csv")
items_cat_en <- merge(items_cat_en, items_full_en[,c("definition", "lexical_class")], all.x = T, 
                      by = "definition") 
lex_en <- items_cat_en %>%
ggplot(aes(d, a1))  + 
  geom_point(data = items_cat_en %>%
               select(-lexical_class), aes(x = d, y = a1), color = 'grey', size = 0.4) +
  geom_point(aes(color=as.factor(lexical_class)), size = 0.4) +
  facet_wrap(~lexical_class)  +
  xlim(-7, 7) +
  ylim(0,7) +
  labs(x = "Item difficulty (d)", y = "Item discrimination (a1)", title = "(A) English") +
  theme(legend.position = "none")

lex <- ggarrange(lex_en, lex_pl)
lex
# ggsave("lexical_classes.jpeg", dpi = 300, width = 200, height = 100, units = "mm")

```


## Item selection in the two CAT-CDIs

```{r}
# Data prep

# POLISH
items_run_pl <- responses_cat_pl %>% select(items) %>% group_by(items) %>% summarise(n = length(items))
items_run_pl <- merge(items_cat_pl, items_run_pl, by.x = "item", by.y = "items", all.x = T)
items_run_pl[is.na(items_run_pl)] <- 0
items_run_pl$never <- ifelse(items_run_pl$n == 0, "never", "at_least_once")

items_run_pl <- items_run_pl %>% 
  mutate(items_perc = (n/115)*100) %>%
  mutate(percent_for_color = ifelse(items_perc == 0, NA, items_perc)) 

# AMERICAN ENGLISH

items_run_en <- resps %>%
  select(subject_id, response_cat, definition)

items_run_en <- items_run_en %>% mutate(
  item_used = case_when(
    response_cat == "no_test" ~ 0,
    .default = 1
  )
)

items_run_en <- items_run_en %>%
  select(definition, item_used) %>%
  group_by(definition) %>%
  mutate(n = sum(item_used)) %>%
  select(definition, n) %>% unique()

# how many participants in resps?
resps %>% select(subject_id) %>% unique() %>% nrow()

items_run_en <- items_run_en %>% 
  mutate(items_perc = (n/204)*100) %>%
  mutate(percent_for_color = ifelse(items_perc == 0, NA, items_perc)) 

items_run_en <- merge(items_run_en, coefs_2pl[,c("definition", "a1", "d")], 
                   all.x = T,
                   by = "definition")

# ame items lack categories
eng_ws_items <- read_csv("data/english/eng_ws_items.csv")
items_run_en <- merge(items_run_en, eng_ws_items[,c("definition", "category")], all.x = T, by = "definition")
rm(eng_ws_items)
```

```{r}
# PL
sum(items_run_pl$n != 0) # 258
round(sum(items_run_pl$n != 0)/count(items_run_pl)*100,2) # 38.74

# EN
sum(items_run_en$n != 0) # 251
round(sum(items_run_en$n != 0)/count(items_run_en)*100,2) # 36.91
```

```{r used-items-fig, fig.width = 10, fig.height = 5, fig.cap = "How often a given item was used in CAT-CDI administrations in the validation study in (A) English and (B) Polish. The items (points) are colored by the percentage of their appearance in the CAT-CDI administrations. Items colored in grey are items never used in any of the CAT-CDI administrations.", fig.pos = '!h', include = T}

# Plotting (un)used items - cloud
# PL
fig2b <- items_run_pl %>%
  mutate(d_bin = cut(d, breaks = seq(-7.5, 7.5, by = 1))) %>%
  ggplot(aes(x = d_bin, y = a1)) +
  geom_jitter(aes(color = percent_for_color), alpha = 0.7, width = 0.2) +  # Points
  geom_boxplot(alpha = 0.2, width = 0.5, outlier.shape = NA) +  # Add boxplots
  scale_color_viridis(option = "D", na.value = "grey", name = "Percent", begin = 1, end = 0) +
  ylim(0, 7.5) +
  labs(
    x = "Difficulty (d)",
    y = "Discrimination (a1)",
    title = "(B) Polish",
    caption = "Grey are unused items"
  ) +
  theme_light() +
  theme(legend.position = c(0.95, 0.85))

# EN
fig2a <- items_run_en %>%
  mutate(d_bin = cut(d, breaks = seq(-7.5, 7.5, by = 1))) %>%
  ggplot(aes(x = d_bin, y = a1)) +
  geom_jitter(aes(color = percent_for_color), alpha = 0.7, width = 0.2) +  # Points
  geom_boxplot(alpha = 0.2, width = 0.5, outlier.shape = NA) +  # Add boxplots
  scale_color_viridis(option = "D", na.value = "grey", name = "Percent", begin = 1, end = 0) +
  ylim(0, 7.5) +
  labs(
    x = "Difficulty (d)",
    y = "Discrimination (a1)",
    title = "(A) English",
    caption = "Grey are unused items"
  ) +
  theme_light() +
  theme(legend.position = c(0.95, 0.85))
fig2 <- ggarrange(fig2a, fig2b, nrow = 1, ncol = 2)
fig2
  
ggsave("fig2.jpeg", dpi = 400, width = 250, height = 100, units = "mm")

```

It is to be expected that a CDI-CAT will not need to administer all the items in the item bank. In fact, in the validation study the English CAT-CDI used `r sum(items_run_en$n != 0)` items (`r round(sum(items_run_en$n != 0)/count(items_run_en)*100,2)`%) and similarly, the Polish CAT-CDI used `r sum(items_run_pl$n != 0)` items (`r round(sum(items_run_pl$n != 0)/count(items_run_pl)*100,2)`%).
By design, a CDI-CAT selects items that are most informative for each participant. This means it draws from a subset of available items--typically those matched to the participant’s current ability estimate in terms of difficulty, and with high discrimination, meaning they effectively distinguish between individuals with abilities close to that estimate. Figure \@ref(fig:used-items-fig) plots the items by their difficulty and discrimination parameters and colors the items (points) by how often they were used in CAT-CDI administrations in English and Polish. A few findings are of note here. First, both CAT-CDIs used items of very low discrimination (i.e, items that do no discriminate well between ability levels). Often that was because for a given difficulty level there were not enough items and CAT-CDI had to use all the items available (this is particularly true of the items on the two ends of difficulty). However, more surprisingly, it is also true of items of medium difficulty, where items of higher discrimination were available (but were not chosen by the CAT algorithm).
<!-- SEE ISSUE #2 https://github.com/karolina-m/catcdi_validation_eng_pl/issues/2. NOTE TO US: I emailed Phil Chalmers, the author of mirtcat and mirt packages in R to ask if he has any idea why this is so -->

```{r}
# ISSUE #2
# https://github.com/karolina-m/catcdi_validation_eng_pl/issues/2

# testing Phil Chalmer's idea that low discrimination items are used early on in CAT administration, when the location of the latent trait estimate is highly uncertain, and therefore having concentrated statistical information at an exact theta location is impractical

# PL

# items of low discrimination that are still run by CAT algorithm
# PL: a1 < 3 and d between -1.5 to 1.5 (in other difficulty/theta levels, CAT is taking all items available, irregardless of their a1, see used-items-fig)
low_a1_items_pl <- items_run_pl %>% filter(n > 0) %>%
     filter(a1 < 2) %>%
     filter(d > -1.5 & d < 1.5) %>% select(item, a1) #12 items like that, and mostly SOUNDS

# add information on item's place (nth item) in administration
responses_cat_pl %>%
     select(items, q_id) %>%
     left_join(low_a1_items_pl, join_by(items == item)) %>% filter(!is.na(a1)) -> low_a1_items_pl

# plot items' position in test by a1
# merge to have item's a1, theta AND item position in test
responses_cat_pl <- merge(responses_cat_pl, items_cat_pl[,c("item", "a1", "d")],
                          all.x = T,
                          by.x = "items", by.y = "item")

# mark the low discrimination items
responses_cat_pl <- responses_cat_pl %>%
     mutate(unlikely_item = case_when(
         a1 < 2 & d > -1.5 & d < 1.5 ~ "yes",
         .default = "no"
     ))

# there should be 12 unique items in the unlikely category
responses_cat_pl %>% select(items, unlikely_item) %>% filter(unlikely_item == "yes") %>% unique() %>% summarise(n()) # 12 --> ok

# plot only the ids where the unlikely items were shown 
# idxs where unlikely_item == "yes"
ids_with_unlikely <- responses_cat_pl %>%
  filter(unlikely_item == "yes") %>%
  distinct(idx)

# theta and se are char --> numeric
responses_cat_pl$theta <- as.numeric(responses_cat_pl$theta)
responses_cat_pl$se_theta <- as.numeric(responses_cat_pl$se_theta)

# plot
responses_cat_pl %>%
  semi_join(ids_with_unlikely, by = "idx") %>% 
  # mutate(se_color = ifelse(se_theta == 0.1, "green", "red")) %>% #none reach acceptable SEM
  ggplot() +
  geom_point(aes(x = q_id, y = a1), color = "blue", alpha = 0.3) +
  geom_point(aes(x = q_id, y = theta), alpha = 0.3) +
  # geom_point(aes(x = q_id, y = se_theta, color = se_color), alpha = 0.3) +
  geom_hline(yintercept = 2, color = "blue", alpha = 0.3) +
  ylim(-4, 7) +
  labs(
    y = "",
    x = "item's position in test",
    title = "Polish data: blue marks item's a1, black marks theta estimate at this item; none reached acceptable SEM (0.1)"
  ) +
  facet_wrap(~ idx, ncol = 2) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  scale_color_identity()

# ggsave("only_idx_with_any_low_a1_item.jpeg", dpi = 300, height = 3000, width = 3000, units = "px")

# EN
low_a1_items_en <- items_run_en %>% filter(n > 0) %>%
     filter(a1 < 2) %>%
     filter(d > -1.5 & d < 1.5) %>% select(definition, a1) #19 items like that, and many are sounds

# add item position in CAT administrations
# is there anywhere to find this? need a more detailed "resps" df
# not here: resps_more <- read.csv("data/english/EngWS_16to36mos_cleaned.csv")


```


Finally, some items keep being shown in many CAT administrations. In English, 3 items appear in more than half of administrations - *"long"* in 64% of administrations, *"make"* in 54% of administrations, and *"last"* in 53% of administrations. They are also high discrimination items in their difficulty bins. "Long" is additionally one of the starting items, i.e. a first item shown to the parent, chosen so that there is high probability the parent can respond positively. In Polish, 3 items appear in more than half of administrations - *"szukać"* (to look for) appearing in 83% of administrations, *"znaleźć"* (to find) appearing in 61% of administrations, and *"babcia"* (grandmother) appearing in 60% of administrations. All three items show very high discrimination. "Szukać" (to look for) and "znaleźć" (to find) are also in top 5 discrimination items in general. "Babcia" (grandmother) is one of the starting items. 

```{r}
items_en_pl <- merge(items_en_pl, items_run_pl[,c("item", "items_perc")], all.x = T, by = "item")
names(items_en_pl)[names(items_en_pl) == "items_perc"] <- "items_perc_pl"

items_en_pl <- merge(items_en_pl, items_run_en[,c("definition", "items_perc")], all.x = T, by = "definition")
names(items_en_pl)[names(items_en_pl) == "items_perc"] <- "items_perc_en"

c3 <- apa_print(cor.test(items_en_pl$items_perc_pl, items_en_pl$items_perc_en, paired = T, method = "spearman")) # .37

```


To check whether the CDI items common in both languages may show similar frequencies in CAT-CDI administrations, we ran Spearman's rank correlation and found that the items frequencies in administrations were weakly correlated, `r c3$full_result`. However, the two CAT-CDIs differed in their potential length, as the English CAT-CDI was set to administer 25--50 items and the Polish CAT-CDI could administer up to 75 items (no minimum was set, but in practice the minimum items administered were 13). As an item is more likely to appear in longer tests (simply due to test length), then frequency of the Polish items could be inflated. <!-- Could it be that, as an item is more likely to appear in longer tests (simply due to test length), frequency of the Polish items could be inflated? Could it influence the item's rank? I could probably recalculate item frequency not per total number of administrations, but per total number of items administered? SEE ISSUE #3 https://github.com/karolina-m/catcdi_validation_eng_pl/issues/3  -->

```{r}

```


## CAT-CDIs' usefullness in research and practice

```{r}
# calculate and add duration_cat for Eng
demo <- demo %>% mutate(
     duration_cat = lubridate::as.duration(last_modified_cat - created_date_cat))

prod_s <- merge(prod_s, demo[,c("subject_id", "duration_cat")], all.x = T, by = "subject_id")

```

```{r}
# mean number of items administered in CAT
# PL
by_child_pl %>% summarise(mean(no_items), #35
                          median(no_items),#23
                          min(no_items), #13
                          max(no_items), #75
                          sd(no_items)) #22.72

# EN
resps_sum <- resps %>% filter(response_cat != "no_test") %>%
     group_by(subject_id) %>%
     summarise(n = length(test_word))

resps_sum %>% summarise(mean(n), #31
                          median(n), #25
                          min(n), #25
                          max(n), #50
                          sd(n)) #10.11

t1 <- apa_print(t.test(resps_sum$n, by_child_pl$no_items))
```

One of the key metrics for CAT-CDI's usefulness is whether it can shorten the CDI administration compared to the full CDI, but still obtain a reliable estimate of child's lexical ability. We have found that CAT-CDIs were significantly shorter to administer: the English CAT-CDI median time was `r duration(median(prod_s$duration_cat))` (median full CDI time was `r duration(median(prod_s$duration_full))`) and the Polish CAT-CDI median time was `r duration(median(by_child_pl$duration_cat))` (median full CDI time was `r duration(median(by_child_pl$duration_full))`). Even though the CAT-CDI in Polish seemed shorter (compared to English CAT-CDI), the number of items administered in the two language versions of CAT-CDI was comparable: English *M* = `r round(mean(resps_sum$n),2)`, *Mdn* = `r median(resps_sum$n)` (25--50 items), Polish *M* = `r round(mean(by_child_pl$no_items),2)`, *Mdn* = `r median(by_child_pl$no_items)` (`r min(by_child_pl$no_items)`--`r max(by_child_pl$no_items)` items).

```{r}
#  SEM

# PL
mean(by_child_pl$cat_theta_se) # 0.11
median(by_child_pl$cat_theta_se) # 0.10

# EN
mean(prod_s$catTheta_SE) # 0.17
median(prod_s$catTheta_SE) # 0.16

t2 <- apa_print(t.test(prod_s$catTheta_SE, by_child_pl$cat_theta_se)) # p < 0.001

cor_age <- apa_print(cor.test(prod_s$catTheta_SE, prod_s$age_full)) # watch out, SE is weakly but significantly correlated with age, and the English validation sample is slightly (but significantly) younger than the Polish one. This differece in SEM between the samples can be partially pulled by age.
```

The two CAT-CDIs differed in their settings as to when to finish the administration. Specifically, the Polish CAT-CDI was set so that the SEM as low as 0.1 be reached (with as few items as possible), and if the SEM could not be lowered to or below 0.1, the CAT-CDI stopped after administering a maximum of 75 items. The English CAT-CDI on the other hand was set to administer a maximum of 50 items, but the administration could be stopped earlier if the SEM of 0.15 or lower was reached. In other words, the Polish CAT-CDI prioritized as low SEM as possible, while the English CAT-CDI prioritized shorter test length. This difference resulted in slightly lower mean SEM in Polish CAT-CDI, compared to English CAT-CDI `r t2$full_result` but comparable mean number of items administered, `r t1$full_result`. However, it should be noted that the Polish and American validation samples differed slightly in age `r t_age$full_result`, and as age is weakly correlated with SEM (`r cor_age$full_result`), this slight difference in age could feed the SEM difference in the two validation samples.

```{r}
# SEM percentiles

# PL
ecdf_fun <- ecdf(as.numeric(by_child_pl$cat_theta_se))
by_child_pl <- by_child_pl %>%
  mutate(cat_theta_se_percentile = ecdf_fun(cat_theta_se) * 100) %>%
     relocate(cat_theta_se_percentile, .after = cat_theta_se)

# EN
ecdf_fun <- ecdf(as.numeric(prod_s$catTheta_SE))
prod_s <- prod_s %>%
  mutate(catTheta_SE_percentile = ecdf_fun(catTheta_SE) * 100) %>%
     relocate(catTheta_SE_percentile, .after = catTheta_SE)

round(sum(by_child_pl$cat_theta_se < 0.2)/count(by_child_pl)*100,1) # 96.5%
round(sum(prod_s$catTheta_SE < 0.2)/count(prod_s)*100,1) # 92.6%

```

In both CAT-CDIs, we have been able to reliably estimate lexical ability for majority of children. For 93% of the American participants, the SEM was lower than 0.2 and for 93% of Polish participants, the SEM was below 0.15 and for `r sum(by_child_pl$above_max_se_cat == "no")` participants (`r round(sum(by_child_pl$above_max_se_cat == "no")/count(by_child_pl)*100,2)`%) the Polish CAT-CDI SEM was 0.1 or lower. The remaining particiapants, i.e. those with higher standard errors of measurement (in other words, lower reliability of ability estimates) were typically those at the extremes of the ability scale--children with either relatively low or relatively high lexical skills (see Figure \@ref(fig:se-fig)).


```{r se-fig, fig.width = 10, fig.height = 5, fig.cap = "Standard Error of Measurement (SEM) by ability estimate in (A) English and (B) Polish.", fig.pos = '!h', include = T}

# PL
fig3b <- by_child_pl %>%
  ggplot(aes(x = cat_theta, y = se_theta)) + geom_point(color = "#00416d", alpha = 0.5) +
  labs(title = "(B) Polish", x = "Ability level", y = "Standard error (SEM)") +
  ylim(0, 0.4) +
  theme_light() +  theme(legend.position = "none")

# EN
prod_s <- prod_s %>% 
  mutate(above_max_se_cat = case_when(
    catTheta_SE > 0.15 ~ "yes",
    .default = "no"
  ))

fig3a <- prod_s %>%
  ggplot(aes(x = catTheta, y = catTheta_SE)) + geom_point(color = "#00416d", alpha = 0.5) +
  labs(title = "(A) English", x = "Ability level", y = "Standard error (SEM)") +
  ylim(0, 0.4) +
  theme_light() +  theme(legend.position = "none")

fig3 <- ggarrange(fig3a, fig3b, ncol = 2)
fig3

```



Next:
- Parental (in)consistency.   



# Discussion

In points for now:    

1. *Strong correlations with full CDI*.   
The CAT-CDIs were strongly correlated with the full CDI versions in both languages, which supports the overall validity of the CAT approach. These correlations held for both monolingual and multilingual participants. However, the Polish sample was small, so further research is needed—and planned—to confirm these findings.    

2. *Cases of extreme divergence*.   
CAT-CDI scores diverged notably from full CDI estimates for only a small number of children in both language groups. In the Polish sample all divergent cases had low SEM, and their full CDIs were unusually short--maybe the full form underestimated their ability? In the English sample, their full CDIs were not very short, but SEM was relatively low, which is good.     

3. *Item paramteres across languages*.   
Item parameters (i.e., difficulty and discrimination) showed moderate correlations across languages. These likely stem from variations in the calibration samples. Still, some semantic categories showed consistent patterns across languages, suggesting underlying structural similarities in lexical development.   

4. *Item selection*.   
Each CAT version used c.a. half of the full CDI item pool. Few items were overused (mostly those with highest discrimination in the item pool or starting items). But we also saw items being chosen for CAT that wouldn't be considered very informative (i.e., of low discrimination). That's something to explore further, I wrote to Phil Chalmers (author of mirt and mirtCAT), maybe he'll be able to help?    

5. *Efficiency and Reliability*.   
CAT-CDIs were significantly shorter than the full CDIs while maintaining high reliability for most children. The few less reliable estimates were for children at the ends of the ability range (children with either very low or very high lexical skills). Comparing Polish and English samples, the ability ranges with low SEM differed (see Figure 3) - this again might be a result of the calibration samples and item parameters? This is a good place to stress the importance of well-balanced, diverse calibration datasets. 
Also, while the CAT-CDI is efficient and useful for screening or initial identification (“pomiar przesiewowy” in Polish), it may be less suited for diagnostic purposes where high precision is needed across the full ability range.

\newpage

# References

::: {#refs custom-style="Bibliography"}
:::

`r cite_r("r-references.bib")`
